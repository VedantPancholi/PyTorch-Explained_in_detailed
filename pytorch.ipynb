{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/vedantpancholi/pytorch?scriptVersionId=216242030\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"2abf2845","metadata":{"papermill":{"duration":0.006235,"end_time":"2025-01-05T18:34:48.110531","exception":false,"start_time":"2025-01-05T18:34:48.104296","status":"completed"},"tags":[]},"source":["# Fashion-MNIST \n","is a dataset of Zalando's article imagesâ€”consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes.\n","\n","Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255. The training and test data sets have 785 columns."]},{"cell_type":"code","execution_count":1,"id":"0f1bc1cf","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2025-01-05T18:34:48.123161Z","iopub.status.busy":"2025-01-05T18:34:48.122768Z","iopub.status.idle":"2025-01-05T18:34:55.624Z","shell.execute_reply":"2025-01-05T18:34:55.623181Z"},"papermill":{"duration":7.510017,"end_time":"2025-01-05T18:34:55.625683","exception":false,"start_time":"2025-01-05T18:34:48.115666","status":"completed"},"tags":[]},"outputs":[],"source":["import torch\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor"]},{"cell_type":"markdown","id":"762857b0","metadata":{"papermill":{"duration":0.004323,"end_time":"2025-01-05T18:34:55.634877","exception":false,"start_time":"2025-01-05T18:34:55.630554","status":"completed"},"tags":[]},"source":["We load the FashionMNIST Dataset with the following **parameters**:\n","- root is the path where the train/test data is stored,\n","- train specifies training or test dataset,\n","- download=True downloads the data from the internet if itâ€™s not available at root.\n","- transform and target_transform specify the feature and label transformations"]},{"cell_type":"code","execution_count":2,"id":"ddc91cbf","metadata":{"execution":{"iopub.execute_input":"2025-01-05T18:34:55.644719Z","iopub.status.busy":"2025-01-05T18:34:55.644374Z","iopub.status.idle":"2025-01-05T18:35:01.188737Z","shell.execute_reply":"2025-01-05T18:35:01.187654Z"},"papermill":{"duration":5.550727,"end_time":"2025-01-05T18:35:01.190019","exception":false,"start_time":"2025-01-05T18:34:55.639292","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26421880/26421880 [00:01<00:00, 15001608.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29515/29515 [00:00<00:00, 263507.18it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4422102/4422102 [00:00<00:00, 4997300.34it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5148/5148 [00:00<00:00, 8352911.80it/s]"]},{"name":"stdout","output_type":"stream","text":["Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["\n","training_data = datasets.FashionMNIST(\n","    root=\"data\",\n","    train=True,\n","    download=True,\n","    transform=ToTensor()\n",")\n","\n","test_data = datasets.FashionMNIST(\n","    root=\"data\",\n","    train=False,\n","    download=True,\n","    transform=ToTensor()\n",")"]},{"cell_type":"markdown","id":"9e185aad","metadata":{"papermill":{"duration":0.005934,"end_time":"2025-01-05T18:35:01.202492","exception":false,"start_time":"2025-01-05T18:35:01.196558","status":"completed"},"tags":[]},"source":["We pass the Dataset as an argument to DataLoader. This wraps an iterable over our dataset, and supports automatic batching, sampling, shuffling and multiprocess data loading. Here we define a batch size of 64, i.e. each element in the dataloader iterable will return a batch of 64 features and labels.\n","\n","**Batch size** refers to the number of samples (data points) that are passed through the model at one time during training or evaluation. It determines how many data samples are processed together in one forward/backward pass through the neural network."]},{"cell_type":"code","execution_count":3,"id":"b9b895d1","metadata":{"execution":{"iopub.execute_input":"2025-01-05T18:35:01.214939Z","iopub.status.busy":"2025-01-05T18:35:01.214688Z","iopub.status.idle":"2025-01-05T18:35:01.309914Z","shell.execute_reply":"2025-01-05T18:35:01.309035Z"},"papermill":{"duration":0.103022,"end_time":"2025-01-05T18:35:01.311333","exception":false,"start_time":"2025-01-05T18:35:01.208311","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n","Shape of y: torch.Size([64]) torch.int64\n"]}],"source":["batch_size = 64\n","\n","# Create data loaders.\n","train_dataloader = DataLoader(training_data, batch_size=batch_size)\n","test_dataloader = DataLoader(test_data, batch_size=batch_size)\n","\n","for X, y in test_dataloader:\n","    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n","    print(f\"Shape of y: {y.shape} {y.dtype}\")\n","    break"]},{"cell_type":"markdown","id":"980857ae","metadata":{"papermill":{"duration":0.006079,"end_time":"2025-01-05T18:35:01.323623","exception":false,"start_time":"2025-01-05T18:35:01.317544","status":"completed"},"tags":[]},"source":["X: The input batch with shape [N, C, H, W]:\n","\n","* N: Batch size (e.g., 64).\n","* C: Number of channels (e.g., 3 for RGB images).\n","* H: Height of the image.\n","* W: Width of the image.\n","\n","y: The corresponding labels for the batch.\n","break: Stops after the first batch, displaying the shape and type of X and y."]},{"cell_type":"markdown","id":"4e9de6d5","metadata":{"papermill":{"duration":0.005927,"end_time":"2025-01-05T18:35:01.335577","exception":false,"start_time":"2025-01-05T18:35:01.32965","status":"completed"},"tags":[]},"source":["# Creating Models\n","To define a neural network in PyTorch, we create a class that inherits from nn.Module. We define the layers of the network in the __init__ function and specify how data will pass through the network in the forward function. To accelerate operations in the neural network, we move it to the GPU or MPS if available."]},{"cell_type":"code","execution_count":4,"id":"07b630b4","metadata":{"execution":{"iopub.execute_input":"2025-01-05T18:35:01.348519Z","iopub.status.busy":"2025-01-05T18:35:01.348294Z","iopub.status.idle":"2025-01-05T18:35:01.350907Z","shell.execute_reply":"2025-01-05T18:35:01.350335Z"},"papermill":{"duration":0.010624,"end_time":"2025-01-05T18:35:01.352195","exception":false,"start_time":"2025-01-05T18:35:01.341571","status":"completed"},"tags":[]},"outputs":[],"source":["# model = NeuralNetwork().to(device)\n","# print(model)"]},{"cell_type":"markdown","id":"53793db8","metadata":{"papermill":{"duration":0.0059,"end_time":"2025-01-05T18:35:01.364104","exception":false,"start_time":"2025-01-05T18:35:01.358204","status":"completed"},"tags":[]},"source":["# Explanation of Layers\n","**Flatten:**\n","Converts 2D images into a 1D vector to pass through fully connected layers.\n","\n","**Linear:**\n","Fully connected layers that perform weighted sum operations followed by bias addition.\n","\n","ReLU:\n","Applies the ReLU activation function: \n","ð‘“\n","(\n","ð‘¥\n",")\n","=\n","max\n","â¡\n","(\n","0\n",",\n","ð‘¥\n",")\n","f(x)=max(0,x).\n","Introduces non-linearity to help the model learn complex patterns.\n","\n","**Sequential:**\n","Groups layers into a single block for simplicity.\n"]},{"cell_type":"code","execution_count":5,"id":"fad11ce1","metadata":{"execution":{"iopub.execute_input":"2025-01-05T18:35:01.376799Z","iopub.status.busy":"2025-01-05T18:35:01.376586Z","iopub.status.idle":"2025-01-05T18:35:02.312394Z","shell.execute_reply":"2025-01-05T18:35:02.311348Z"},"papermill":{"duration":0.943879,"end_time":"2025-01-05T18:35:02.313876","exception":false,"start_time":"2025-01-05T18:35:01.369997","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Using cuda device\n","NeuralNetwork(\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n","  (linear_relu_stack): Sequential(\n","    (0): Linear(in_features=784, out_features=512, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=512, out_features=512, bias=True)\n","    (3): ReLU()\n","    (4): Linear(in_features=512, out_features=10, bias=True)\n","  )\n",")\n","Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[-0.0097, -0.0138,  0.0351,  ..., -0.0088, -0.0273,  0.0213],\n","        [ 0.0322, -0.0218,  0.0122,  ...,  0.0155, -0.0179, -0.0007]],\n","       device='cuda:0', grad_fn=<SliceBackward0>) \n","\n","Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([-0.0207,  0.0300], device='cuda:0', grad_fn=<SliceBackward0>) \n","\n","Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[ 0.0226,  0.0273, -0.0098,  ...,  0.0163, -0.0167, -0.0275],\n","        [-0.0071,  0.0094, -0.0301,  ...,  0.0324,  0.0409,  0.0329]],\n","       device='cuda:0', grad_fn=<SliceBackward0>) \n","\n","Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([-0.0155, -0.0355], device='cuda:0', grad_fn=<SliceBackward0>) \n","\n","Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[-0.0105,  0.0186, -0.0050,  ..., -0.0087, -0.0231, -0.0377],\n","        [-0.0008, -0.0105, -0.0171,  ...,  0.0325, -0.0294, -0.0238]],\n","       device='cuda:0', grad_fn=<SliceBackward0>) \n","\n","Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([-0.0286, -0.0350], device='cuda:0', grad_fn=<SliceBackward0>) \n","\n"]}],"source":["# Get cpu, gpu or mps device for training.\n","device = (\n","    \"cuda\"\n","    if torch.cuda.is_available()\n","    else \"mps\"\n","    if torch.backends.mps.is_available()\n","    else \"cpu\"\n",")\n","print(f\"Using {device} device\")\n","\n","# Define model\n","class NeuralNetwork(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.flatten = nn.Flatten()\n","        self.linear_relu_stack = nn.Sequential(\n","            nn.Linear(28*28, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 10)\n","        )\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        logits = self.linear_relu_stack(x)\n","        # print(logists)\n","        return logits\n","\n","model = NeuralNetwork().to(device)\n","print(model)\n","\n","for name, param in model.named_parameters():\n","    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"]},{"cell_type":"markdown","id":"285815f6","metadata":{"papermill":{"duration":0.006003,"end_time":"2025-01-05T18:35:02.326794","exception":false,"start_time":"2025-01-05T18:35:02.320791","status":"completed"},"tags":[]},"source":["# Optimizing the Model Parameters\n","**nn.CrossEntropyLoss**\n","* This criterion computes the cross entropy loss between input logits and target.\n","\n","\n","For more info of Optimizer is here [https://pytorch.org/docs/stable/optim.html](http://)"]},{"cell_type":"code","execution_count":6,"id":"1fd9a4ae","metadata":{"execution":{"iopub.execute_input":"2025-01-05T18:35:02.340703Z","iopub.status.busy":"2025-01-05T18:35:02.340462Z","iopub.status.idle":"2025-01-05T18:35:02.344463Z","shell.execute_reply":"2025-01-05T18:35:02.343681Z"},"papermill":{"duration":0.012234,"end_time":"2025-01-05T18:35:02.34568","exception":false,"start_time":"2025-01-05T18:35:02.333446","status":"completed"},"tags":[]},"outputs":[],"source":["loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"]},{"cell_type":"code","execution_count":7,"id":"844cca01","metadata":{"execution":{"iopub.execute_input":"2025-01-05T18:35:02.359627Z","iopub.status.busy":"2025-01-05T18:35:02.359396Z","iopub.status.idle":"2025-01-05T18:35:02.363036Z","shell.execute_reply":"2025-01-05T18:35:02.362159Z"},"papermill":{"duration":0.01205,"end_time":"2025-01-05T18:35:02.364333","exception":false,"start_time":"2025-01-05T18:35:02.352283","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["SGD (\n","Parameter Group 0\n","    dampening: 0\n","    differentiable: False\n","    foreach: None\n","    fused: None\n","    lr: 0.001\n","    maximize: False\n","    momentum: 0\n","    nesterov: False\n","    weight_decay: 0\n",")\n"]}],"source":["print(optimizer)"]},{"cell_type":"markdown","id":"413bc8dd","metadata":{"papermill":{"duration":0.006077,"end_time":"2025-01-05T18:35:02.376935","exception":false,"start_time":"2025-01-05T18:35:02.370858","status":"completed"},"tags":[]},"source":["**optimizer.zero_grad()** is a crucial step in the training loop when using optimizers in PyTorch. It resets the gradients of all model parameters before computing the gradients during the backward pass.\n","\n","**optimizer.step()** is called to update the modelâ€™s parameters based on the gradients stored in the .grad attributes. The optimizer adjusts the parameters to minimize the loss, typically by moving them in the opposite direction of the gradients.\n","\n","\n","Instead of SGD we can use \n","**Adam Optimizer**:\n","Adam (Adaptive Moment Estimation) is an extension of SGD that computes adaptive learning rates for each parameter. It uses both the first moment (mean) and second moment (uncentered variance) of the gradients to scale the learning rate for each parameter.\n","\n","> optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"]},{"cell_type":"code","execution_count":8,"id":"8a84ba54","metadata":{"execution":{"iopub.execute_input":"2025-01-05T18:35:02.390042Z","iopub.status.busy":"2025-01-05T18:35:02.389801Z","iopub.status.idle":"2025-01-05T18:35:02.394523Z","shell.execute_reply":"2025-01-05T18:35:02.393731Z"},"papermill":{"duration":0.012439,"end_time":"2025-01-05T18:35:02.39567","exception":false,"start_time":"2025-01-05T18:35:02.383231","status":"completed"},"tags":[]},"outputs":[],"source":["def train(dataloader, model, loss_fn, optimizer):\n","    size = len(dataloader.dataset)\n","    model.train()\n","    for batch, (X, y) in enumerate(dataloader):\n","        X, y = X.to(device), y.to(device)\n","\n","        # Compute prediction error\n","        pred = model(X)\n","        loss = loss_fn(pred, y)\n","\n","        # Backpropagation\n","        loss.backward()\n","        optimizer.step()\n","        optimizer.zero_grad()\n","\n","        if batch % 100 == 0:\n","            loss, current = loss.item(), (batch + 1) * len(X)\n","            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"]},{"cell_type":"markdown","id":"1a351892","metadata":{"papermill":{"duration":0.006064,"end_time":"2025-01-05T18:35:02.408184","exception":false,"start_time":"2025-01-05T18:35:02.40212","status":"completed"},"tags":[]},"source":["We also check the modelâ€™s performance against the test dataset to ensure it is learning.\n","\n","**torch.argmax(..., axis=1):** \n","- This computes the index of the class with the highest predicted score (logit) for each test sample.\n","- For binary classification, it will return 0 or 1 based on the higher score.\n","axis=1 means we are applying this operation along the class dimension."]},{"cell_type":"code","execution_count":9,"id":"97167e46","metadata":{"execution":{"iopub.execute_input":"2025-01-05T18:35:02.421038Z","iopub.status.busy":"2025-01-05T18:35:02.420817Z","iopub.status.idle":"2025-01-05T18:35:02.425259Z","shell.execute_reply":"2025-01-05T18:35:02.42449Z"},"papermill":{"duration":0.012092,"end_time":"2025-01-05T18:35:02.426377","exception":false,"start_time":"2025-01-05T18:35:02.414285","status":"completed"},"tags":[]},"outputs":[],"source":["def test(dataloader, model, loss_fn):\n","    size = len(dataloader.dataset)\n","    num_batches = len(dataloader)\n","    model.eval()\n","    test_loss, correct = 0, 0\n","    with torch.no_grad():\n","        for X, y in dataloader:\n","            X, y = X.to(device), y.to(device)\n","            pred = model(X)\n","            test_loss += loss_fn(pred, y).item()\n","            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n","    test_loss /= num_batches\n","    correct /= size\n","    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"]},{"cell_type":"code","execution_count":10,"id":"69d25272","metadata":{"execution":{"iopub.execute_input":"2025-01-05T18:35:02.439326Z","iopub.status.busy":"2025-01-05T18:35:02.439065Z","iopub.status.idle":"2025-01-05T18:35:41.954895Z","shell.execute_reply":"2025-01-05T18:35:41.953837Z"},"papermill":{"duration":39.52373,"end_time":"2025-01-05T18:35:41.956281","exception":false,"start_time":"2025-01-05T18:35:02.432551","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1\n","-------------------------------\n","loss: 2.307847  [   64/60000]\n","loss: 2.292337  [ 6464/60000]\n","loss: 2.273041  [12864/60000]\n","loss: 2.268509  [19264/60000]\n","loss: 2.250344  [25664/60000]\n","loss: 2.225611  [32064/60000]\n","loss: 2.238950  [38464/60000]\n","loss: 2.202011  [44864/60000]\n","loss: 2.203968  [51264/60000]\n","loss: 2.171115  [57664/60000]\n","Test Error: \n"," Accuracy: 44.1%, Avg loss: 2.165017 \n","\n","Epoch 2\n","-------------------------------\n","loss: 2.176085  [   64/60000]\n","loss: 2.165334  [ 6464/60000]\n","loss: 2.108520  [12864/60000]\n","loss: 2.128055  [19264/60000]\n","loss: 2.069658  [25664/60000]\n","loss: 2.016087  [32064/60000]\n","loss: 2.049450  [38464/60000]\n","loss: 1.967141  [44864/60000]\n","loss: 1.978970  [51264/60000]\n","loss: 1.899716  [57664/60000]\n","Test Error: \n"," Accuracy: 52.3%, Avg loss: 1.899212 \n","\n","Epoch 3\n","-------------------------------\n","loss: 1.927643  [   64/60000]\n","loss: 1.899173  [ 6464/60000]\n","loss: 1.785386  [12864/60000]\n","loss: 1.836100  [19264/60000]\n","loss: 1.711725  [25664/60000]\n","loss: 1.660042  [32064/60000]\n","loss: 1.694843  [38464/60000]\n","loss: 1.589411  [44864/60000]\n","loss: 1.616798  [51264/60000]\n","loss: 1.515215  [57664/60000]\n","Test Error: \n"," Accuracy: 61.7%, Avg loss: 1.530576 \n","\n","Epoch 4\n","-------------------------------\n","loss: 1.588485  [   64/60000]\n","loss: 1.559209  [ 6464/60000]\n","loss: 1.416420  [12864/60000]\n","loss: 1.493511  [19264/60000]\n","loss: 1.368879  [25664/60000]\n","loss: 1.358714  [32064/60000]\n","loss: 1.380788  [38464/60000]\n","loss: 1.300045  [44864/60000]\n","loss: 1.334753  [51264/60000]\n","loss: 1.244829  [57664/60000]\n","Test Error: \n"," Accuracy: 63.3%, Avg loss: 1.263952 \n","\n","Epoch 5\n","-------------------------------\n","loss: 1.335509  [   64/60000]\n","loss: 1.321936  [ 6464/60000]\n","loss: 1.162988  [12864/60000]\n","loss: 1.268681  [19264/60000]\n","loss: 1.145663  [25664/60000]\n","loss: 1.161973  [32064/60000]\n","loss: 1.188352  [38464/60000]\n","loss: 1.119230  [44864/60000]\n","loss: 1.159730  [51264/60000]\n","loss: 1.085183  [57664/60000]\n","Test Error: \n"," Accuracy: 64.4%, Avg loss: 1.097857 \n","\n","Done!\n"]}],"source":["epochs = 5\n","for t in range(epochs):\n","    print(f\"Epoch {t+1}\\n-------------------------------\")\n","    train(train_dataloader, model, loss_fn, optimizer)\n","    test(test_dataloader, model, loss_fn)\n","print(\"Done!\")"]},{"cell_type":"markdown","id":"d33a1921","metadata":{"papermill":{"duration":0.008796,"end_time":"2025-01-05T18:35:41.974386","exception":false,"start_time":"2025-01-05T18:35:41.96559","status":"completed"},"tags":[]},"source":["# Saving Models\n","A common way to save a model is to serialize the internal state dictionary (containing the model parameters)."]},{"cell_type":"code","execution_count":11,"id":"7d9f7f33","metadata":{"execution":{"iopub.execute_input":"2025-01-05T18:35:41.991973Z","iopub.status.busy":"2025-01-05T18:35:41.991744Z","iopub.status.idle":"2025-01-05T18:35:42.003029Z","shell.execute_reply":"2025-01-05T18:35:42.002339Z"},"papermill":{"duration":0.021794,"end_time":"2025-01-05T18:35:42.004394","exception":false,"start_time":"2025-01-05T18:35:41.9826","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Saved PyTorch Model State to model.pth\n"]}],"source":["torch.save(model.state_dict(), \"model.pth\")\n","print(\"Saved PyTorch Model State to model.pth\")"]},{"cell_type":"markdown","id":"8837b8e8","metadata":{"papermill":{"duration":0.008087,"end_time":"2025-01-05T18:35:42.020877","exception":false,"start_time":"2025-01-05T18:35:42.01279","status":"completed"},"tags":[]},"source":["# Loading Models\n","The process for loading a model includes re-creating the model structure and loading the state dictionary into it."]},{"cell_type":"code","execution_count":12,"id":"e5407d70","metadata":{"execution":{"iopub.execute_input":"2025-01-05T18:35:42.038293Z","iopub.status.busy":"2025-01-05T18:35:42.037972Z","iopub.status.idle":"2025-01-05T18:35:42.05615Z","shell.execute_reply":"2025-01-05T18:35:42.055464Z"},"papermill":{"duration":0.028322,"end_time":"2025-01-05T18:35:42.057388","exception":false,"start_time":"2025-01-05T18:35:42.029066","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["model = NeuralNetwork().to(device)\n","model.load_state_dict(torch.load(\"model.pth\", weights_only=True))"]},{"cell_type":"markdown","id":"9d880aad","metadata":{"papermill":{"duration":0.008531,"end_time":"2025-01-05T18:35:42.074316","exception":false,"start_time":"2025-01-05T18:35:42.065785","status":"completed"},"tags":[]},"source":["**This model can now be used to make predictions.**"]},{"cell_type":"code","execution_count":13,"id":"2c6cee1a","metadata":{"execution":{"iopub.execute_input":"2025-01-05T18:35:42.092119Z","iopub.status.busy":"2025-01-05T18:35:42.091882Z","iopub.status.idle":"2025-01-05T18:35:42.139496Z","shell.execute_reply":"2025-01-05T18:35:42.138805Z"},"papermill":{"duration":0.057673,"end_time":"2025-01-05T18:35:42.140727","exception":false,"start_time":"2025-01-05T18:35:42.083054","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"]}],"source":["classes = [\n","    \"T-shirt/top\",\n","    \"Trouser\",\n","    \"Pullover\",\n","    \"Dress\",\n","    \"Coat\",\n","    \"Sandal\",\n","    \"Shirt\",\n","    \"Sneaker\",\n","    \"Bag\",\n","    \"Ankle boot\",\n","]\n","\n","\n","model.eval()\n","x, y = test_data[0][0], test_data[0][1]\n","with torch.no_grad():\n","    x = x.to(device)\n","    pred = model(x)\n","    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n","    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"]},{"cell_type":"code","execution_count":14,"id":"c20d2d43","metadata":{"execution":{"iopub.execute_input":"2025-01-05T18:35:42.158624Z","iopub.status.busy":"2025-01-05T18:35:42.158409Z","iopub.status.idle":"2025-01-05T18:35:42.191202Z","shell.execute_reply":"2025-01-05T18:35:42.189469Z"},"papermill":{"duration":0.043071,"end_time":"2025-01-05T18:35:42.192531","exception":false,"start_time":"2025-01-05T18:35:42.14946","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["OrderedDict([('linear_relu_stack.0.weight', tensor([[-0.0097, -0.0138,  0.0351,  ..., -0.0088, -0.0273,  0.0213],\n","        [ 0.0322, -0.0218,  0.0122,  ...,  0.0155, -0.0179, -0.0007],\n","        [ 0.0265, -0.0068,  0.0016,  ...,  0.0153,  0.0203,  0.0025],\n","        ...,\n","        [ 0.0160,  0.0304,  0.0331,  ..., -0.0088, -0.0330, -0.0182],\n","        [ 0.0017, -0.0033,  0.0025,  ..., -0.0205, -0.0357, -0.0047],\n","        [ 0.0288,  0.0306,  0.0072,  ...,  0.0270, -0.0015,  0.0019]],\n","       device='cuda:0')), ('linear_relu_stack.0.bias', tensor([-0.0222,  0.0359,  0.0316, -0.0355,  0.0376,  0.0043, -0.0192,  0.0211,\n","        -0.0071,  0.0285, -0.0095, -0.0009,  0.0282,  0.0181,  0.0244,  0.0305,\n","         0.0143,  0.0087, -0.0075, -0.0117, -0.0039,  0.0259,  0.0195,  0.0197,\n","         0.0352,  0.0257, -0.0059, -0.0174, -0.0286,  0.0248, -0.0151, -0.0289,\n","        -0.0239, -0.0283,  0.0151,  0.0168, -0.0121,  0.0258, -0.0171,  0.0312,\n","        -0.0183,  0.0172,  0.0282, -0.0312,  0.0099, -0.0013,  0.0184,  0.0076,\n","        -0.0021, -0.0111, -0.0252, -0.0121, -0.0160, -0.0259,  0.0016,  0.0147,\n","         0.0213,  0.0460,  0.0227,  0.0087,  0.0335,  0.0346, -0.0023, -0.0171,\n","         0.0373,  0.0008,  0.0282, -0.0036,  0.0183,  0.0265, -0.0137,  0.0083,\n","        -0.0031,  0.0250,  0.0304, -0.0032, -0.0150,  0.0166,  0.0176, -0.0006,\n","         0.0040,  0.0351, -0.0135,  0.0003,  0.0180,  0.0363, -0.0249, -0.0079,\n","        -0.0032,  0.0227,  0.0226,  0.0085,  0.0142,  0.0012,  0.0220, -0.0248,\n","         0.0320,  0.0176,  0.0120, -0.0258,  0.0275,  0.0137, -0.0086, -0.0301,\n","         0.0073,  0.0200, -0.0068, -0.0134,  0.0317,  0.0277, -0.0110, -0.0137,\n","         0.0161, -0.0186,  0.0046, -0.0166, -0.0136,  0.0002,  0.0070,  0.0312,\n","         0.0008, -0.0216, -0.0229,  0.0033,  0.0260,  0.0173, -0.0185, -0.0185,\n","         0.0055,  0.0124, -0.0082, -0.0263,  0.0315,  0.0227,  0.0058, -0.0260,\n","        -0.0090, -0.0116, -0.0057,  0.0260,  0.0133,  0.0082,  0.0323,  0.0126,\n","         0.0291,  0.0205,  0.0242,  0.0253, -0.0310, -0.0238,  0.0224,  0.0156,\n","         0.0208, -0.0236,  0.0078,  0.0138, -0.0107,  0.0289,  0.0044, -0.0075,\n","         0.0215,  0.0427,  0.0273, -0.0037, -0.0308, -0.0316,  0.0184, -0.0097,\n","         0.0187,  0.0286,  0.0106,  0.0226, -0.0117, -0.0085,  0.0035, -0.0364,\n","        -0.0179, -0.0235,  0.0301,  0.0415, -0.0267, -0.0352,  0.0238,  0.0098,\n","         0.0303,  0.0117, -0.0234,  0.0189,  0.0194, -0.0154, -0.0037, -0.0336,\n","        -0.0231, -0.0360, -0.0112, -0.0130,  0.0036, -0.0244, -0.0059,  0.0033,\n","         0.0359, -0.0190,  0.0122, -0.0106,  0.0195,  0.0137, -0.0266,  0.0213,\n","        -0.0037, -0.0063, -0.0168,  0.0308,  0.0326, -0.0248,  0.0341,  0.0228,\n","        -0.0111, -0.0229,  0.0249,  0.0207, -0.0196, -0.0314, -0.0195,  0.0030,\n","        -0.0229, -0.0049,  0.0164,  0.0375, -0.0177, -0.0114, -0.0056,  0.0445,\n","         0.0152, -0.0237, -0.0199, -0.0158, -0.0011,  0.0336, -0.0281,  0.0026,\n","        -0.0153, -0.0132,  0.0246,  0.0064, -0.0065, -0.0228,  0.0317,  0.0087,\n","        -0.0194, -0.0096, -0.0210,  0.0040,  0.0150, -0.0201, -0.0070,  0.0256,\n","         0.0033,  0.0015, -0.0096, -0.0023,  0.0111, -0.0164,  0.0166, -0.0236,\n","         0.0108,  0.0235,  0.0029,  0.0314,  0.0055, -0.0250,  0.0227,  0.0301,\n","        -0.0182,  0.0266, -0.0296, -0.0289, -0.0253, -0.0157,  0.0247,  0.0231,\n","         0.0255,  0.0037, -0.0013,  0.0341, -0.0298,  0.0437,  0.0191,  0.0244,\n","         0.0215, -0.0246,  0.0164, -0.0271, -0.0257,  0.0292, -0.0018,  0.0002,\n","        -0.0300,  0.0205,  0.0243, -0.0327,  0.0291,  0.0257,  0.0104,  0.0318,\n","        -0.0099, -0.0290,  0.0217, -0.0288, -0.0337,  0.0139, -0.0253,  0.0360,\n","        -0.0300, -0.0030, -0.0347,  0.0405, -0.0271, -0.0258, -0.0026,  0.0178,\n","         0.0113,  0.0171, -0.0144,  0.0028,  0.0095, -0.0162, -0.0076,  0.0349,\n","        -0.0273,  0.0340,  0.0038, -0.0198,  0.0211, -0.0007,  0.0199, -0.0158,\n","        -0.0130, -0.0139, -0.0337, -0.0100,  0.0292,  0.0218,  0.0096, -0.0166,\n","        -0.0186, -0.0147, -0.0262, -0.0231,  0.0097,  0.0102, -0.0299, -0.0118,\n","         0.0075, -0.0200,  0.0385, -0.0167, -0.0065, -0.0345, -0.0115,  0.0205,\n","         0.0117,  0.0130, -0.0107,  0.0211,  0.0244, -0.0288,  0.0376,  0.0252,\n","         0.0026,  0.0070,  0.0308,  0.0292,  0.0193,  0.0053,  0.0047, -0.0085,\n","        -0.0012,  0.0122,  0.0329,  0.0242, -0.0236, -0.0213, -0.0262,  0.0329,\n","        -0.0042, -0.0301, -0.0104,  0.0272, -0.0025, -0.0297,  0.0368, -0.0290,\n","         0.0338, -0.0282, -0.0109, -0.0150,  0.0123, -0.0189,  0.0348,  0.0240,\n","        -0.0373, -0.0215, -0.0083, -0.0230, -0.0021, -0.0124, -0.0293,  0.0330,\n","        -0.0072,  0.0297, -0.0312, -0.0250,  0.0231, -0.0156, -0.0339,  0.0168,\n","         0.0176,  0.0110, -0.0093, -0.0013, -0.0151, -0.0036,  0.0228, -0.0144,\n","         0.0120,  0.0470,  0.0380,  0.0115,  0.0156, -0.0216,  0.0387, -0.0115,\n","         0.0397,  0.0242, -0.0064,  0.0099,  0.0281, -0.0151,  0.0021,  0.0392,\n","         0.0176,  0.0376,  0.0207,  0.0291,  0.0122,  0.0019,  0.0169, -0.0203,\n","        -0.0110,  0.0245, -0.0254, -0.0068, -0.0338,  0.0266,  0.0076, -0.0207,\n","         0.0358, -0.0244, -0.0047,  0.0129,  0.0036,  0.0265,  0.0296,  0.0303,\n","         0.0146,  0.0306, -0.0222, -0.0130,  0.0038, -0.0093, -0.0205,  0.0002,\n","        -0.0101, -0.0343,  0.0242,  0.0058,  0.0264, -0.0017,  0.0141, -0.0139,\n","         0.0175,  0.0367,  0.0239, -0.0144,  0.0204,  0.0216, -0.0073, -0.0308,\n","        -0.0209, -0.0116, -0.0188,  0.0058,  0.0087, -0.0026, -0.0111, -0.0054,\n","         0.0230,  0.0350,  0.0063, -0.0096,  0.0380, -0.0154,  0.0322, -0.0262,\n","         0.0022,  0.0035,  0.0203, -0.0010, -0.0321,  0.0088,  0.0125, -0.0008],\n","       device='cuda:0')), ('linear_relu_stack.2.weight', tensor([[ 0.0226,  0.0279, -0.0106,  ...,  0.0172, -0.0169, -0.0277],\n","        [-0.0071,  0.0088, -0.0291,  ...,  0.0321,  0.0412,  0.0357],\n","        [-0.0059, -0.0364, -0.0233,  ..., -0.0295, -0.0327, -0.0038],\n","        ...,\n","        [ 0.0248, -0.0229,  0.0325,  ...,  0.0138, -0.0315, -0.0171],\n","        [ 0.0179,  0.0066,  0.0021,  ..., -0.0175,  0.0012,  0.0184],\n","        [-0.0140, -0.0336,  0.0357,  ...,  0.0278, -0.0280,  0.0276]],\n","       device='cuda:0')), ('linear_relu_stack.2.bias', tensor([-1.2644e-02, -2.8778e-02, -3.6055e-02, -2.5985e-02,  1.9399e-02,\n","        -1.4091e-02,  4.0188e-02,  5.8780e-02,  4.5004e-02,  2.2715e-02,\n","         2.9508e-02,  1.5850e-02, -3.9277e-02,  2.1387e-02, -2.9133e-02,\n","         1.1245e-02, -5.5679e-03, -3.5838e-02,  2.4428e-02,  1.0258e-02,\n","        -1.3911e-02, -3.3940e-03, -3.7108e-02, -1.4314e-02,  2.9148e-02,\n","         9.7189e-03,  3.6597e-03,  3.7427e-02, -2.4514e-02,  8.2236e-03,\n","        -1.0437e-02, -6.1389e-03, -1.1220e-03,  3.8892e-02,  1.3914e-02,\n","         2.0027e-03,  5.4035e-02, -1.6875e-02, -3.4627e-02, -4.0403e-02,\n","        -1.4015e-02,  3.5179e-02,  3.7082e-02, -1.8975e-02,  1.8494e-02,\n","         2.5772e-02, -1.8593e-02,  3.8390e-02,  3.6760e-02, -3.7369e-03,\n","        -3.0496e-02,  2.9496e-02,  2.7569e-02,  9.3767e-03,  2.7867e-02,\n","        -1.1398e-02,  3.9544e-02, -2.5340e-05,  2.5258e-02,  3.0046e-03,\n","        -9.6369e-03, -2.8607e-02, -4.3292e-02,  5.0174e-02,  3.9738e-02,\n","         5.0020e-02,  2.8557e-03,  3.3250e-02, -3.0137e-02,  2.8852e-02,\n","        -1.0596e-02,  1.4851e-02,  5.4933e-02,  1.4469e-02,  3.2925e-02,\n","        -3.3281e-02, -1.8000e-02,  4.0121e-03, -2.2260e-02,  3.7439e-02,\n","        -2.7554e-02, -4.1767e-02, -2.8574e-02,  4.9522e-03,  3.5030e-02,\n","         1.2074e-02,  7.3061e-03, -1.9089e-02, -2.3863e-02,  3.7143e-02,\n","         1.3105e-02,  1.2437e-02,  2.7859e-02, -2.8427e-02, -2.5027e-02,\n","        -2.2638e-02, -6.4389e-03,  3.1746e-03,  1.9028e-02, -1.7701e-02,\n","         8.8355e-03, -3.4043e-03,  5.3115e-02, -2.8478e-02,  5.1238e-02,\n","         1.9266e-03,  2.9845e-02, -3.5607e-02,  1.5469e-02,  1.6855e-03,\n","        -3.0945e-02,  7.6324e-03,  8.6662e-03, -1.8273e-03, -1.3793e-02,\n","         1.2751e-02,  1.6606e-02, -2.0444e-02, -3.5458e-02, -2.9507e-03,\n","         1.8818e-02,  5.0877e-02,  3.0885e-02,  2.1487e-02, -8.6380e-03,\n","        -4.3554e-02,  1.3331e-02,  4.1951e-02,  2.5469e-02,  1.2942e-02,\n","         3.1180e-03, -3.8227e-02, -7.2201e-04, -2.2253e-02,  1.2974e-02,\n","         3.7894e-02, -3.2334e-02, -3.6707e-02, -2.2049e-02, -9.0015e-03,\n","        -1.1231e-02,  8.8724e-03, -4.2171e-02,  3.2927e-02,  3.2443e-02,\n","        -1.0827e-03, -5.9016e-04, -3.0324e-02,  7.6320e-03,  4.1480e-03,\n","        -3.9451e-02, -8.1274e-03, -3.2377e-02,  4.1275e-02,  3.3409e-03,\n","         2.8130e-02,  2.9412e-02,  2.3771e-02, -4.1166e-02,  3.1783e-02,\n","         3.3028e-03,  5.6659e-02,  4.3637e-02, -3.0719e-02, -6.6891e-03,\n","         1.4352e-02, -1.2871e-02, -3.8793e-02, -3.4404e-02, -3.4946e-02,\n","        -2.2051e-02,  2.1534e-02,  1.4941e-02, -9.6355e-03, -1.1622e-02,\n","        -1.1168e-03, -7.4094e-04, -3.8479e-02,  1.5786e-02,  1.5533e-02,\n","        -3.5460e-02, -1.4191e-02, -2.6821e-02,  2.6877e-02,  7.0622e-03,\n","         2.3855e-02, -4.3716e-02, -2.4725e-02,  3.8422e-02,  5.1040e-02,\n","         3.6092e-02,  5.1671e-02, -3.7244e-02,  7.4992e-04,  1.0601e-02,\n","         5.7339e-03, -1.2293e-02,  4.0532e-02, -4.9496e-03,  3.1981e-02,\n","         2.2886e-02, -2.1200e-02,  6.0701e-02,  2.2507e-02,  4.3875e-02,\n","         5.6774e-02,  4.0791e-02, -2.2596e-02, -9.6104e-04,  1.8935e-02,\n","        -3.8251e-02, -8.9492e-03, -1.5616e-02, -4.6788e-02,  3.6013e-02,\n","         2.3585e-02, -5.9979e-04, -3.2130e-03,  4.0032e-02,  2.6568e-02,\n","         5.5087e-02,  4.7011e-02,  3.3683e-02,  1.0905e-02,  1.7613e-02,\n","         3.8154e-02, -4.1476e-03,  3.9224e-02, -3.4705e-02,  2.1910e-03,\n","         1.1635e-02,  5.7754e-03,  2.6125e-02, -2.5013e-02, -4.3760e-02,\n","        -8.7143e-03,  1.0313e-02,  3.2188e-02,  1.5407e-02,  4.1604e-02,\n","        -1.5846e-02,  2.0863e-02,  1.2756e-03,  1.6313e-03, -4.1698e-02,\n","        -2.8678e-02,  5.1629e-02,  5.5574e-02,  3.3186e-02,  6.0716e-03,\n","         1.8413e-02,  2.0430e-02, -3.5195e-03,  2.0451e-02, -5.7657e-03,\n","         2.4995e-02,  3.3050e-02, -1.8697e-02,  3.8509e-02, -2.3232e-02,\n","        -1.1219e-02,  6.8814e-04,  2.2248e-02, -4.9176e-03,  1.6200e-02,\n","         5.2977e-02, -1.7367e-02, -4.1687e-02, -2.0712e-02, -1.5084e-02,\n","         4.6083e-02,  2.5709e-02, -4.3507e-03, -3.4990e-05, -1.6514e-02,\n","         2.2710e-02, -2.3559e-02,  2.7902e-02, -1.0337e-02, -3.0822e-02,\n","         1.1348e-03, -8.4460e-04,  2.0693e-02, -2.0735e-02, -8.8536e-04,\n","         5.1425e-03, -2.6541e-02, -1.1444e-02,  3.6169e-02,  3.0929e-02,\n","        -2.3946e-03, -5.4984e-03,  4.7283e-02, -2.9988e-02,  1.4037e-02,\n","        -3.2598e-02,  1.1860e-02,  2.4418e-02, -2.3919e-02,  1.0907e-02,\n","        -3.7651e-02, -3.4792e-02, -1.2568e-02,  1.4869e-02,  4.0985e-02,\n","         1.0706e-03, -2.7247e-02,  3.1254e-02,  7.0765e-04,  3.3544e-02,\n","        -2.0215e-02, -1.4961e-03,  3.0747e-02, -3.4420e-02,  1.4932e-02,\n","         3.2871e-02,  2.3315e-03,  3.8107e-02, -2.4439e-02,  3.4973e-02,\n","         2.4659e-02, -3.8240e-02,  2.6909e-02,  1.6727e-02, -9.0197e-03,\n","         2.3617e-02, -5.9591e-03,  4.8997e-02,  1.1161e-02, -1.4152e-03,\n","         3.9492e-02, -3.4544e-02,  3.3329e-02, -2.4437e-02,  3.2000e-03,\n","        -3.0968e-02, -3.1178e-02, -1.6934e-02,  1.1293e-02, -2.1289e-03,\n","         5.6682e-02, -1.1386e-03,  7.0450e-03, -2.4240e-02,  4.7338e-02,\n","         4.8527e-03, -2.8550e-02,  4.5808e-02,  2.6758e-02,  2.3854e-02,\n","        -6.1766e-03,  4.3136e-02, -1.3155e-02,  1.4232e-02,  1.8818e-02,\n","        -1.0524e-02, -2.5122e-03, -1.7255e-02, -2.1342e-02,  2.2360e-02,\n","         1.6447e-02, -3.5518e-02, -3.4270e-02,  2.5510e-02, -5.1166e-03,\n","         1.7521e-02, -3.2750e-02, -3.0500e-02, -3.6171e-02,  5.3977e-02,\n","         1.3463e-02,  6.8170e-03,  3.8871e-03,  4.0520e-02,  1.5423e-02,\n","         2.2108e-03, -1.7329e-02, -4.9099e-03, -7.2768e-03, -1.1887e-02,\n","        -3.1234e-02, -3.6500e-02, -1.4803e-02, -2.8051e-02,  1.8295e-02,\n","        -4.1513e-02,  1.4143e-02,  3.4891e-02, -1.1523e-02, -3.7411e-02,\n","        -4.1076e-02,  1.2912e-02,  1.2410e-02,  4.7735e-02, -1.9118e-02,\n","        -6.0599e-03, -3.6291e-02,  4.7416e-03,  4.4917e-02, -2.3537e-03,\n","         4.4262e-02, -1.5604e-02, -1.8717e-02,  4.4307e-02,  3.7183e-02,\n","        -1.1569e-02,  9.7707e-03, -3.9153e-02,  3.6283e-02, -2.3294e-02,\n","        -3.2812e-03,  2.6882e-02, -2.9338e-02, -2.8552e-02, -3.0128e-02,\n","        -2.5658e-02, -1.8026e-02,  2.2986e-02, -1.5477e-02,  1.4061e-02,\n","        -1.7091e-02,  2.1316e-02,  3.5173e-02, -1.2319e-02, -4.6092e-02,\n","        -1.5358e-02, -2.0670e-02, -2.5470e-02,  4.3148e-02,  1.8082e-02,\n","        -3.4318e-02, -1.8465e-02,  3.0848e-02,  3.6692e-02,  2.5035e-02,\n","        -3.6319e-02,  7.2247e-03, -5.9796e-03, -2.2490e-03, -5.2139e-03,\n","         3.8476e-02, -2.4169e-02,  2.1968e-02,  1.4190e-02,  1.1878e-02,\n","        -2.5365e-02, -3.9593e-02,  3.5372e-02, -3.3788e-02, -2.4455e-02,\n","         1.9889e-02,  9.4232e-03, -3.5087e-02,  5.5832e-02,  1.0765e-02,\n","         1.5417e-02,  2.2497e-02, -2.8786e-02, -1.8142e-02,  4.5651e-02,\n","         3.7826e-02, -4.1292e-02, -3.6151e-02, -1.0870e-02,  2.0717e-02,\n","        -2.4485e-02,  1.7812e-02,  3.6995e-02,  3.0369e-02, -3.4631e-02,\n","         1.2273e-02, -1.5205e-03,  2.8656e-03, -2.3087e-02, -3.4792e-03,\n","         1.1543e-03, -3.2641e-02,  3.7042e-02, -1.2636e-02, -4.0408e-02,\n","         2.3094e-02, -4.1946e-03, -2.6425e-02, -1.3112e-02, -9.4465e-03,\n","        -3.3371e-03,  2.0779e-02,  4.4991e-02, -3.4101e-02,  1.8070e-02,\n","        -9.2672e-04,  1.3444e-02, -2.4263e-02,  3.8607e-02, -3.1677e-02,\n","        -4.0404e-02,  1.6034e-02,  5.1919e-02,  3.2509e-03,  5.2022e-02,\n","        -8.1738e-03, -3.3137e-02,  1.5414e-02,  2.3192e-02, -3.4457e-02,\n","        -4.5108e-03,  3.0986e-02,  6.7803e-03, -6.5428e-03, -1.0124e-02,\n","         4.2530e-02,  3.6815e-02], device='cuda:0')), ('linear_relu_stack.4.weight', tensor([[-0.0035,  0.0107, -0.0233,  ..., -0.0195, -0.0599, -0.0429],\n","        [-0.0070,  0.0043, -0.0240,  ...,  0.0514, -0.0856, -0.0274],\n","        [ 0.0364,  0.0040, -0.0174,  ..., -0.0413,  0.0113, -0.0317],\n","        ...,\n","        [-0.0431,  0.0610, -0.0175,  ..., -0.0031,  0.0323, -0.0100],\n","        [-0.0406, -0.0012,  0.0064,  ..., -0.0360,  0.0998, -0.0487],\n","        [ 0.0097, -0.0555,  0.0820,  ...,  0.0471,  0.0532,  0.0137]],\n","       device='cuda:0')), ('linear_relu_stack.4.bias', tensor([-0.0333,  0.0008, -0.0060,  0.0549, -0.0591,  0.0947, -0.0377,  0.0271,\n","        -0.0417, -0.0406], device='cuda:0'))])\n"]},{"name":"stderr","output_type":"stream","text":["<ipython-input-14-29d7ae474ccf>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  state_dict = torch.load(\"model.pth\")\n"]}],"source":["state_dict = torch.load(\"model.pth\")\n","print(state_dict)\n"]},{"cell_type":"code","execution_count":null,"id":"95c67277","metadata":{"papermill":{"duration":0.008722,"end_time":"2025-01-05T18:35:42.210234","exception":false,"start_time":"2025-01-05T18:35:42.201512","status":"completed"},"tags":[]},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30822,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":58.926507,"end_time":"2025-01-05T18:35:43.845876","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-01-05T18:34:44.919369","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}